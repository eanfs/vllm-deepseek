# ğŸ” DeepSeek-OCR vLLM éƒ¨ç½²

é€šè¿‡ Docker Compose ä¸€é”®éƒ¨ç½² [DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) æ¨¡å‹ï¼ŒåŸºäº [vLLM](https://docs.vllm.ai/) æ¨ç†å¼•æ“ï¼Œæä¾› OpenAI å…¼å®¹ APIã€‚

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | è¦æ±‚ |
|------|------|
| **GPU** | NVIDIA GPUï¼Œâ‰¥16GB æ˜¾å­˜ (æ¨è A100/L40S/4090) |
| **é©±åŠ¨** | NVIDIA Driver â‰¥ 525.60.13 |
| **Docker** | Docker Engine â‰¥ 24.0 |
| **NVIDIA å®¹å™¨å·¥å…·** | [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) |
| **ç£ç›˜** | å»ºè®®é¢„ç•™ â‰¥30GB ç”¨äºæ¨¡å‹ç¼“å­˜ |

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### 1. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
# ç¼–è¾‘ .envï¼Œå¡«å…¥ä½ çš„ HuggingFace Token
vim .env
```

### 2. å¯åŠ¨æœåŠ¡

```bash
docker compose up -d
```

### 3. æŸ¥çœ‹å¯åŠ¨æ—¥å¿—

```bash
# ç­‰å¾…å‡ºç° "Started server process" è¡¨ç¤ºå¯åŠ¨æˆåŠŸ
docker compose logs -f
```

### 4. éªŒè¯æœåŠ¡

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# æŸ¥çœ‹å·²åŠ è½½çš„æ¨¡å‹
curl http://localhost:8000/v1/models
```

## ğŸ“¡ API ä½¿ç”¨

### curl è°ƒç”¨ç¤ºä¾‹

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-ai/DeepSeek-OCR",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
              "url": "https://ofasys-multimodal-wlcb-3-toshanghai.oss-accelerate.aliyuncs.com/wpf272043/keepme/image/receipt.png"
            }
          },
          {
            "type": "text",
            "text": "Free OCR."
          }
        ]
      }
    ],
    "max_tokens": 4096,
    "temperature": 0.0,
    "skip_special_tokens": false,
    "vllm_xargs": {
      "ngram_size": 30,
      "window_size": 90,
      "whitelist_token_ids": [128821, 128822]
    }
  }'
```

### Python è°ƒç”¨ç¤ºä¾‹

```bash
pip install openai
python test_ocr.py
```

è¯¦è§ [test_ocr.py](./test_ocr.py)ã€‚

## ğŸ’¡ å¸¸ç”¨ OCR æç¤ºè¯

| æç¤ºè¯ | è¯´æ˜ |
|--------|------|
| `Free OCR.` | è‡ªç”±æ ¼å¼ OCRï¼Œè‡ªåŠ¨è¯†åˆ«æ–‡æœ¬ |
| `<\|grounding\|>Convert the document to markdown.` | å°†æ–‡æ¡£è½¬æ¢ä¸º Markdown æ ¼å¼ |
| `Read all the text in the image.` | è¯»å–å›¾ç‰‡ä¸­æ‰€æœ‰æ–‡æœ¬ |
| `Convert the table to markdown.` | å°†è¡¨æ ¼è½¬æ¢ä¸º Markdown |

> **æç¤º**: DeepSeek-OCR ä½¿ç”¨**æ™®é€šæç¤ºè¯**æ•ˆæœä¼˜äºæŒ‡ä»¤æ ¼å¼ï¼ˆinstruction formatï¼‰ã€‚

## âš™ï¸ é…ç½®è¯´æ˜

æ‰€æœ‰é…ç½®é¡¹åœ¨ `.env` æ–‡ä»¶ä¸­ä¿®æ”¹ï¼š

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `HF_TOKEN` | (ç©º) | HuggingFace Token |
| `VLLM_IMAGE_TAG` | `latest` | vLLM Docker é•œåƒç‰ˆæœ¬ |
| `HOST_PORT` | `8000` | ä¸»æœºç«¯å£å· |
| `GPU_COUNT` | `all` | GPU æ•°é‡ |
| `MAX_MODEL_LEN` | `8192` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `GPU_MEMORY_UTILIZATION` | `0.90` | GPU æ˜¾å­˜ä½¿ç”¨ç‡ |
| `HF_CACHE_DIR` | `~/.cache/huggingface` | æ¨¡å‹ç¼“å­˜è·¯å¾„ |

## ğŸ›  å¸¸ç”¨å‘½ä»¤

```bash
# å¯åŠ¨
docker compose up -d

# åœæ­¢
docker compose down

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f

# é‡å¯
docker compose restart

# æŸ¥çœ‹èµ„æºä½¿ç”¨
docker stats deepseek-ocr
```

## â“ å¸¸è§é—®é¢˜

### æ¨¡å‹ä¸‹è½½å¾ˆæ…¢ï¼Ÿ
è®¾ç½® HuggingFace é•œåƒï¼ˆä¸­å›½å¤§é™†ç”¨æˆ·ï¼‰ï¼š
```bash
# åœ¨ .env ä¸­æ·»åŠ  / æˆ–åœ¨ docker-compose.yml çš„ environment ä¸­æ·»åŠ 
HF_ENDPOINT=https://hf-mirror.com
```

### æ˜¾å­˜ä¸è¶³ (OOM)ï¼Ÿ
- é™ä½ `GPU_MEMORY_UTILIZATION`ï¼ˆå¦‚ `0.80`ï¼‰
- å‡å° `MAX_MODEL_LEN`ï¼ˆå¦‚ `4096`ï¼‰

### å¥åº·æ£€æŸ¥å¤±è´¥ï¼Ÿ
æ¨¡å‹é¦–æ¬¡åŠ è½½è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚æŸ¥çœ‹æ—¥å¿—ç¡®è®¤åŠ è½½è¿›åº¦ï¼š
```bash
docker compose logs -f vllm
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [vLLM Docker éƒ¨ç½²æ–‡æ¡£](https://docs.vllm.ai/en/stable/deployment/docker/)
- [DeepSeek-OCR æ¨¡å‹å¡ç‰‡](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
- [vLLM DeepSeek-OCR ä½¿ç”¨æŒ‡å—](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html)
- [DeepSeek-OCR GitHub](https://github.com/deepseek-ai/DeepSeek-OCR)
